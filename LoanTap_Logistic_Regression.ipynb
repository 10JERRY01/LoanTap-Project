{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "# --- Configuration ---\n",
        "DATA_FILE = 'logistic_regression.csv'\n",
        "TARGET_VARIABLE = 'loan_status'\n",
        "POSITIVE_CLASS = 'Charged Off' # Assuming 'Charged Off' is the event of interest (default/NPA)\n",
        "NEGATIVE_CLASS = 'Fully Paid'"
      ],
      "metadata": {
        "id": "SR-VlftNIjT_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load and Inspect Data ---\n",
        "print(\"--- 1. Loading and Inspecting Data ---\")\n",
        "try:\n",
        "    df = pd.read_csv(DATA_FILE)\n",
        "    print(f\"Dataset loaded successfully: {DATA_FILE}\")\n",
        "    print(f\"Shape of the dataset: {df.shape}\")\n",
        "    print(\"\\nFirst 5 rows:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nData Types:\")\n",
        "    print(df.info())\n",
        "    print(\"\\nMissing Values (Initial Check):\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\nStatistical Summary (Numerical Features):\")\n",
        "    print(df.describe())\n",
        "    print(\"\\nStatistical Summary (Categorical Features):\")\n",
        "    print(df.describe(include='object'))\n",
        "\n",
        "    # --- Answering Initial Questions (Based on Raw Loaded Data) ---\n",
        "    print(\"\\n--- Answering Initial Questions (Raw Data) ---\")\n",
        "\n",
        "    # Q1: Percentage of customers who fully paid\n",
        "    try:\n",
        "        fully_paid_percentage = (df[TARGET_VARIABLE] == NEGATIVE_CLASS).mean() * 100\n",
        "        print(f\"\\nQ1: Percentage of customers who fully paid: {fully_paid_percentage:.2f}%\")\n",
        "    except KeyError:\n",
        "        print(f\"\\nQ1: Target variable '{TARGET_VARIABLE}' not found.\")\n",
        "        fully_paid_percentage = 0\n",
        "\n",
        "    # Q2: Correlation between Loan Amount and Installment (Requires numeric calculation later)\n",
        "    # Placeholder - will be calculated after numeric conversion if needed, or during correlation analysis\n",
        "\n",
        "    # Q3: Majority home ownership\n",
        "    try:\n",
        "        majority_ownership = df['home_ownership'].mode()[0]\n",
        "        print(f\"Q3: The majority of people have home ownership as: {majority_ownership}\")\n",
        "    except KeyError:\n",
        "        print(\"Q3: 'home_ownership' column not found.\")\n",
        "\n",
        "    # Q4: Grade 'A' and full payment\n",
        "    try:\n",
        "        grade_a_df = df[df['grade'] == 'A']\n",
        "        if not grade_a_df.empty and TARGET_VARIABLE in grade_a_df.columns:\n",
        "             grade_a_fully_paid_prob = (grade_a_df[TARGET_VARIABLE] == NEGATIVE_CLASS).mean()\n",
        "        else:\n",
        "             grade_a_fully_paid_prob = 0\n",
        "\n",
        "        if TARGET_VARIABLE in df.columns:\n",
        "            overall_fully_paid_prob = (df[TARGET_VARIABLE] == NEGATIVE_CLASS).mean()\n",
        "        else:\n",
        "            overall_fully_paid_prob = 0\n",
        "\n",
        "        # Simple check: Are Grade A more likely than average?\n",
        "        grade_a_more_likely = grade_a_fully_paid_prob > overall_fully_paid_prob\n",
        "        print(f\"Q4: People with grade 'A' are more likely to fully pay their loan: {grade_a_more_likely} (Prob: {grade_a_fully_paid_prob:.2f} vs Overall: {overall_fully_paid_prob:.2f})\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Q4: Column '{e}' not found for calculation.\")\n",
        "    except Exception as e:\n",
        "         print(f\"Q4: Error calculating grade A probability: {e}\")\n",
        "\n",
        "\n",
        "    # Q5: Top 2 afforded job titles (Based on frequency)\n",
        "    try:\n",
        "        # Impute missing titles temporarily for counting\n",
        "        top_2_titles = df['emp_title'].fillna('Missing').value_counts().head(2).index.tolist()\n",
        "        print(f\"Q5: Top 2 most frequent job titles (raw): {top_2_titles}\")\n",
        "    except KeyError:\n",
        "        print(\"Q5: 'emp_title' column not found.\")\n",
        "\n",
        "    print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Data file '{DATA_FILE}' not found. Please ensure it's in the correct directory.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during data loading: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oPMrYqEIX47O",
        "outputId": "1b0918ad-93d2-4fe1-d163-0587ce76d28f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Loading and Inspecting Data ---\n",
            "Dataset loaded successfully: logistic_regression.csv\n",
            "Shape of the dataset: (396030, 27)\n",
            "\n",
            "First 5 rows:\n",
            "   loan_amnt        term  int_rate  installment grade sub_grade  \\\n",
            "0    10000.0   36 months     11.44       329.48     B        B4   \n",
            "1     8000.0   36 months     11.99       265.68     B        B5   \n",
            "2    15600.0   36 months     10.49       506.97     B        B3   \n",
            "3     7200.0   36 months      6.49       220.65     A        A2   \n",
            "4    24375.0   60 months     17.27       609.33     C        C5   \n",
            "\n",
            "                 emp_title emp_length home_ownership  annual_inc  \\\n",
            "0                Marketing  10+ years           RENT    117000.0   \n",
            "1          Credit analyst     4 years       MORTGAGE     65000.0   \n",
            "2             Statistician   < 1 year           RENT     43057.0   \n",
            "3          Client Advocate    6 years           RENT     54000.0   \n",
            "4  Destiny Management Inc.    9 years       MORTGAGE     55000.0   \n",
            "\n",
            "  verification_status   issue_d  loan_status             purpose  \\\n",
            "0        Not Verified  Jan-2015   Fully Paid            vacation   \n",
            "1        Not Verified  Jan-2015   Fully Paid  debt_consolidation   \n",
            "2     Source Verified  Jan-2015   Fully Paid         credit_card   \n",
            "3        Not Verified  Nov-2014   Fully Paid         credit_card   \n",
            "4            Verified  Apr-2013  Charged Off         credit_card   \n",
            "\n",
            "                     title    dti earliest_cr_line  open_acc  pub_rec  \\\n",
            "0                 Vacation  26.24         Jun-1990      16.0      0.0   \n",
            "1       Debt consolidation  22.05         Jul-2004      17.0      0.0   \n",
            "2  Credit card refinancing  12.79         Aug-2007      13.0      0.0   \n",
            "3  Credit card refinancing   2.60         Sep-2006       6.0      0.0   \n",
            "4    Credit Card Refinance  33.95         Mar-1999      13.0      0.0   \n",
            "\n",
            "   revol_bal  revol_util  total_acc initial_list_status application_type  \\\n",
            "0    36369.0        41.8       25.0                   w       INDIVIDUAL   \n",
            "1    20131.0        53.3       27.0                   f       INDIVIDUAL   \n",
            "2    11987.0        92.2       26.0                   f       INDIVIDUAL   \n",
            "3     5472.0        21.5       13.0                   f       INDIVIDUAL   \n",
            "4    24584.0        69.8       43.0                   f       INDIVIDUAL   \n",
            "\n",
            "   mort_acc  pub_rec_bankruptcies  \\\n",
            "0       0.0                   0.0   \n",
            "1       3.0                   0.0   \n",
            "2       0.0                   0.0   \n",
            "3       0.0                   0.0   \n",
            "4       1.0                   0.0   \n",
            "\n",
            "                                             address  \n",
            "0     0174 Michelle Gateway\\r\\nMendozaberg, OK 22690  \n",
            "1  1076 Carney Fort Apt. 347\\r\\nLoganmouth, SD 05113  \n",
            "2  87025 Mark Dale Apt. 269\\r\\nNew Sabrina, WV 05113  \n",
            "3            823 Reid Ford\\r\\nDelacruzside, MA 00813  \n",
            "4             679 Luna Roads\\r\\nGreggshire, VA 11650  \n",
            "\n",
            "Data Types:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 396030 entries, 0 to 396029\n",
            "Data columns (total 27 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   loan_amnt             396030 non-null  float64\n",
            " 1   term                  396030 non-null  object \n",
            " 2   int_rate              396030 non-null  float64\n",
            " 3   installment           396030 non-null  float64\n",
            " 4   grade                 396030 non-null  object \n",
            " 5   sub_grade             396030 non-null  object \n",
            " 6   emp_title             373103 non-null  object \n",
            " 7   emp_length            377729 non-null  object \n",
            " 8   home_ownership        396030 non-null  object \n",
            " 9   annual_inc            396030 non-null  float64\n",
            " 10  verification_status   396030 non-null  object \n",
            " 11  issue_d               396030 non-null  object \n",
            " 12  loan_status           396030 non-null  object \n",
            " 13  purpose               396030 non-null  object \n",
            " 14  title                 394274 non-null  object \n",
            " 15  dti                   396030 non-null  float64\n",
            " 16  earliest_cr_line      396030 non-null  object \n",
            " 17  open_acc              396030 non-null  float64\n",
            " 18  pub_rec               396030 non-null  float64\n",
            " 19  revol_bal             396030 non-null  float64\n",
            " 20  revol_util            395754 non-null  float64\n",
            " 21  total_acc             396030 non-null  float64\n",
            " 22  initial_list_status   396030 non-null  object \n",
            " 23  application_type      396030 non-null  object \n",
            " 24  mort_acc              358235 non-null  float64\n",
            " 25  pub_rec_bankruptcies  395495 non-null  float64\n",
            " 26  address               396030 non-null  object \n",
            "dtypes: float64(12), object(15)\n",
            "memory usage: 81.6+ MB\n",
            "None\n",
            "\n",
            "Missing Values (Initial Check):\n",
            "loan_amnt                   0\n",
            "term                        0\n",
            "int_rate                    0\n",
            "installment                 0\n",
            "grade                       0\n",
            "sub_grade                   0\n",
            "emp_title               22927\n",
            "emp_length              18301\n",
            "home_ownership              0\n",
            "annual_inc                  0\n",
            "verification_status         0\n",
            "issue_d                     0\n",
            "loan_status                 0\n",
            "purpose                     0\n",
            "title                    1756\n",
            "dti                         0\n",
            "earliest_cr_line            0\n",
            "open_acc                    0\n",
            "pub_rec                     0\n",
            "revol_bal                   0\n",
            "revol_util                276\n",
            "total_acc                   0\n",
            "initial_list_status         0\n",
            "application_type            0\n",
            "mort_acc                37795\n",
            "pub_rec_bankruptcies      535\n",
            "address                     0\n",
            "dtype: int64\n",
            "\n",
            "Statistical Summary (Numerical Features):\n",
            "           loan_amnt       int_rate    installment    annual_inc  \\\n",
            "count  396030.000000  396030.000000  396030.000000  3.960300e+05   \n",
            "mean    14113.888089      13.639400     431.849698  7.420318e+04   \n",
            "std      8357.441341       4.472157     250.727790  6.163762e+04   \n",
            "min       500.000000       5.320000      16.080000  0.000000e+00   \n",
            "25%      8000.000000      10.490000     250.330000  4.500000e+04   \n",
            "50%     12000.000000      13.330000     375.430000  6.400000e+04   \n",
            "75%     20000.000000      16.490000     567.300000  9.000000e+04   \n",
            "max     40000.000000      30.990000    1533.810000  8.706582e+06   \n",
            "\n",
            "                 dti       open_acc        pub_rec     revol_bal  \\\n",
            "count  396030.000000  396030.000000  396030.000000  3.960300e+05   \n",
            "mean       17.379514      11.311153       0.178191  1.584454e+04   \n",
            "std        18.019092       5.137649       0.530671  2.059184e+04   \n",
            "min         0.000000       0.000000       0.000000  0.000000e+00   \n",
            "25%        11.280000       8.000000       0.000000  6.025000e+03   \n",
            "50%        16.910000      10.000000       0.000000  1.118100e+04   \n",
            "75%        22.980000      14.000000       0.000000  1.962000e+04   \n",
            "max      9999.000000      90.000000      86.000000  1.743266e+06   \n",
            "\n",
            "          revol_util      total_acc       mort_acc  pub_rec_bankruptcies  \n",
            "count  395754.000000  396030.000000  358235.000000         395495.000000  \n",
            "mean       53.791749      25.414744       1.813991              0.121648  \n",
            "std        24.452193      11.886991       2.147930              0.356174  \n",
            "min         0.000000       2.000000       0.000000              0.000000  \n",
            "25%        35.800000      17.000000       0.000000              0.000000  \n",
            "50%        54.800000      24.000000       1.000000              0.000000  \n",
            "75%        72.900000      32.000000       3.000000              0.000000  \n",
            "max       892.300000     151.000000      34.000000              8.000000  \n",
            "\n",
            "Statistical Summary (Categorical Features):\n",
            "              term   grade sub_grade emp_title emp_length home_ownership  \\\n",
            "count       396030  396030    396030    373103     377729         396030   \n",
            "unique           2       7        35    173105         11              6   \n",
            "top      36 months       B        B3   Teacher  10+ years       MORTGAGE   \n",
            "freq        302005  116018     26655      4389     126041         198348   \n",
            "\n",
            "       verification_status   issue_d loan_status             purpose  \\\n",
            "count               396030    396030      396030              396030   \n",
            "unique                   3       115           2                  14   \n",
            "top               Verified  Oct-2014  Fully Paid  debt_consolidation   \n",
            "freq                139563     14846      318357              234507   \n",
            "\n",
            "                     title earliest_cr_line initial_list_status  \\\n",
            "count               394274           396030              396030   \n",
            "unique               48816              684                   2   \n",
            "top     Debt consolidation         Oct-2000                   f   \n",
            "freq                152472             3017              238066   \n",
            "\n",
            "       application_type                      address  \n",
            "count            396030                       396030  \n",
            "unique                3                       393700  \n",
            "top          INDIVIDUAL  USS Johnson\\r\\nFPO AE 48052  \n",
            "freq             395319                            8  \n",
            "\n",
            "--- Answering Initial Questions (Raw Data) ---\n",
            "\n",
            "Q1: Percentage of customers who fully paid: 80.39%\n",
            "Q3: The majority of people have home ownership as: MORTGAGE\n",
            "Q4: People with grade 'A' are more likely to fully pay their loan: True (Prob: 0.94 vs Overall: 0.80)\n",
            "Q5: Top 2 most frequent job titles (raw): ['Missing', 'Teacher']\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Exploratory Data Analysis (EDA) ---\n",
        "print(\"--- 2. Exploratory Data Analysis (EDA) ---\")\n",
        "\n",
        "# Check Target Variable Distribution\n",
        "print(\"\\nTarget Variable Distribution (loan_status):\")\n",
        "print(df[TARGET_VARIABLE].value_counts(normalize=True) * 100)\n",
        "sns.countplot(x=TARGET_VARIABLE, data=df)\n",
        "plt.title('Distribution of Loan Status')\n",
        "plt.savefig('loan_status_distribution.png') # Save plot\n",
        "plt.close()\n",
        "print(\"Saved plot: loan_status_distribution.png\")\n",
        "\n",
        "# --- Univariate Analysis (Example: loan_amnt) ---\n",
        "print(\"\\nUnivariate Analysis Example (loan_amnt):\")\n",
        "sns.histplot(df['loan_amnt'], kde=True, bins=30)\n",
        "plt.title('Distribution of Loan Amount')\n",
        "plt.savefig('loan_amnt_distribution.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: loan_amnt_distribution.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Hej9KmNZYAxE",
        "outputId": "ee807082-4755-4b07-f5f2-05e7d80a6765"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Exploratory Data Analysis (EDA) ---\n",
            "\n",
            "Target Variable Distribution (loan_status):\n",
            "loan_status\n",
            "Fully Paid     80.387092\n",
            "Charged Off    19.612908\n",
            "Name: proportion, dtype: float64\n",
            "Saved plot: loan_status_distribution.png\n",
            "\n",
            "Univariate Analysis Example (loan_amnt):\n",
            "Saved plot: loan_amnt_distribution.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bivariate Analysis (Example: loan_status vs loan_amnt) ---\n",
        "print(\"\\nBivariate Analysis Example (loan_status vs loan_amnt):\")\n",
        "sns.boxplot(x=TARGET_VARIABLE, y='loan_amnt', data=df)\n",
        "plt.title('Loan Amount vs Loan Status')\n",
        "plt.savefig('loan_amnt_vs_status.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: loan_amnt_vs_status.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5FcJd3cvYFKa",
        "outputId": "d04e90e0-a95d-4da7-d7d3-18fca4e78bd6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bivariate Analysis Example (loan_status vs loan_amnt):\n",
            "Saved plot: loan_amnt_vs_status.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Correlation Analysis ---\n",
        "print(\"\\nCorrelation Analysis (Numerical Features):\")\n",
        "# Select only numeric types for correlation\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "correlation_matrix = df[numeric_cols].corr()\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm') # Annot=True can be slow for many features\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.savefig('correlation_matrix.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: correlation_matrix.png\")\n",
        "print(\"\\nCorrelation with loan_amnt and installment:\")\n",
        "print(f\"Correlation(loan_amnt, installment): {correlation_matrix.loc['loan_amnt', 'installment']:.4f}\")\n",
        "\n",
        "print(\"\\nEDA plots saved as PNG files.\")\n",
        "print(\"-\" * 50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HUUQbR1jYJkd",
        "outputId": "98d10d31-67b7-4630-9567-e85bcfd50e43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correlation Analysis (Numerical Features):\n",
            "Saved plot: correlation_matrix.png\n",
            "\n",
            "Correlation with loan_amnt and installment:\n",
            "Correlation(loan_amnt, installment): 0.9539\n",
            "\n",
            "EDA plots saved as PNG files.\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Feature Engineering ---\n",
        "print(\"--- 3. Feature Engineering ---\")\n",
        "\n",
        "# Drop less useful/complex columns for baseline (Keeping emp_title and address initially)\n",
        "cols_to_drop = ['title', 'sub_grade', 'issue_d'] # Removed 'emp_title', 'address'\n",
        "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
        "print(f\"Dropped columns: {cols_to_drop}\")\n",
        "\n",
        "# Convert 'term' to numeric\n",
        "df['term'] = df['term'].apply(lambda term: int(term.split()[0]))\n",
        "print(\"Converted 'term' to numeric.\")\n",
        "\n",
        "# Convert 'emp_length' to numeric\n",
        "def parse_emp_length(length):\n",
        "    if pd.isna(length):\n",
        "        return 0 # Assume 0 for missing\n",
        "    elif '< 1 year' in length:\n",
        "        return 0\n",
        "    elif '10+ years' in length:\n",
        "        return 10\n",
        "    else:\n",
        "        return int(length.split()[0])\n",
        "\n",
        "df['emp_length'] = df['emp_length'].apply(parse_emp_length)\n",
        "print(\"Converted 'emp_length' to numeric.\")\n",
        "\n",
        "# Convert 'earliest_cr_line' to years of credit history\n",
        "# Assuming the analysis is done relative to the latest loan issue date in the dataset\n",
        "# For simplicity, let's just extract the year and calculate difference from a fixed recent year (e.g., 2017 or max year in data)\n",
        "# A more robust approach would use issue_d if it wasn't dropped, or a fixed reference date.\n",
        "try:\n",
        "    # Try parsing with 'mixed' format for robustness\n",
        "    df['earliest_cr_line_dt'] = pd.to_datetime(df['earliest_cr_line'], format='mixed', errors='coerce')\n",
        "    df.dropna(subset=['earliest_cr_line_dt'], inplace=True) # Drop rows where date couldn't be parsed\n",
        "    df['earliest_cr_line_year'] = df['earliest_cr_line_dt'].dt.year\n",
        "    # Using 2017 as a reference year based on typical LendingClub data vintage\n",
        "    reference_year = 2017\n",
        "    df['credit_history_length'] = reference_year - df['earliest_cr_line_year']\n",
        "    # Drop original and intermediate date columns\n",
        "    df.drop(columns=['earliest_cr_line', 'earliest_cr_line_dt', 'earliest_cr_line_year'], inplace=True)\n",
        "    print(\"Created 'credit_history_length' feature.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not process 'earliest_cr_line': {e}. Skipping feature creation.\")\n",
        "    # If parsing fails, drop the original column anyway to avoid issues later\n",
        "    if 'earliest_cr_line' in df.columns:\n",
        "        df.drop(columns=['earliest_cr_line'], inplace=True)\n",
        "\n",
        "# Extract State from Address\n",
        "# Assuming address format like \"...\\r\\nCity ST Zip\" or \"... City, ST Zip\"\n",
        "# Extract the two-letter code before the zip code (last part of the string)\n",
        "try:\n",
        "    df['state'] = df['address'].str.extract(r'([A-Z]{2})\\s+\\d{5}$') # Extracts ST from 'ST 12345' at end\n",
        "    # Handle cases where state might be missing or format differs - fillna with 'Missing'\n",
        "    df['state'].fillna('Missing', inplace=True)\n",
        "    print(\"Extracted 'state' feature from address.\")\n",
        "    # Drop the original address column now\n",
        "    df.drop(columns=['address'], inplace=True)\n",
        "except KeyError:\n",
        "    print(\"Could not find 'address' column to extract state.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error extracting state from address: {e}\")\n",
        "    # Drop address column if extraction fails\n",
        "    if 'address' in df.columns:\n",
        "        df.drop(columns=['address'], inplace=True)\n",
        "\n",
        "\n",
        "# Create binary flags\n",
        "for col in ['pub_rec', 'mort_acc', 'pub_rec_bankruptcies']:\n",
        "    if col in df.columns:\n",
        "        flag_col_name = f'{col}_flag'\n",
        "        df[flag_col_name] = df[col].apply(lambda x: 1 if pd.notna(x) and x > 0 else 0)\n",
        "        print(f\"Created binary flag: {flag_col_name}\")\n",
        "\n",
        "print(\"Feature engineering steps completed.\")\n",
        "print(\"-\" * 50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PHdGRQhuYMfV",
        "outputId": "010af533-eb7c-404b-91a6-3599c4e14fb2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Feature Engineering ---\n",
            "Dropped columns: ['title', 'sub_grade', 'issue_d']\n",
            "Converted 'term' to numeric.\n",
            "Converted 'emp_length' to numeric.\n",
            "Created 'credit_history_length' feature.\n",
            "Extracted 'state' feature from address.\n",
            "Created binary flag: pub_rec_flag\n",
            "Created binary flag: mort_acc_flag\n",
            "Created binary flag: pub_rec_bankruptcies_flag\n",
            "Feature engineering steps completed.\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Data Preprocessing (Initial Steps) ---\n",
        "print(\"--- 4. Data Preprocessing (Initial Steps) ---\")\n",
        "\n",
        "# Encode Target Variable\n",
        "df[TARGET_VARIABLE] = df[TARGET_VARIABLE].apply(lambda x: 1 if x == POSITIVE_CLASS else 0)\n",
        "print(f\"Encoded target variable '{TARGET_VARIABLE}' (1 for '{POSITIVE_CLASS}', 0 for '{NEGATIVE_CLASS}')\")\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(TARGET_VARIABLE, axis=1)\n",
        "y = df[TARGET_VARIABLE]\n",
        "\n",
        "# Identify numerical and categorical features AFTER feature engineering\n",
        "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(f\"\\nNumerical features ({len(numerical_features)}): {numerical_features}\")\n",
        "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
        "\n",
        "# Placeholder for Pipeline (Imputation, Scaling, Encoding) and Train-Test Split\n",
        "# Define preprocessing steps\n",
        "# Numerical features: Impute with median, then scale\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical features: Impute with a constant value, then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # Ignore categories not seen during training\n",
        "])\n",
        "\n",
        "# Create the preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns (like flags) if any weren't explicitly categorized\n",
        ")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Data split into training and testing sets.\")\n",
        "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing set shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
        "print(\"-\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Rtc4vm2vYVJD",
        "outputId": "8586bc7e-647b-4f8f-bcb3-2e50cdfe0208"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 4. Data Preprocessing (Initial Steps) ---\n",
            "Encoded target variable 'loan_status' (1 for 'Charged Off', 0 for 'Fully Paid')\n",
            "\n",
            "Numerical features (18): ['loan_amnt', 'term', 'int_rate', 'installment', 'emp_length', 'annual_inc', 'dti', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'mort_acc', 'pub_rec_bankruptcies', 'credit_history_length', 'pub_rec_flag', 'mort_acc_flag', 'pub_rec_bankruptcies_flag']\n",
            "Categorical features (8): ['grade', 'emp_title', 'home_ownership', 'verification_status', 'purpose', 'initial_list_status', 'application_type', 'state']\n",
            "Data split into training and testing sets.\n",
            "Training set shape: X_train=(316824, 26), y_train=(316824,)\n",
            "Testing set shape: X_test=(79206, 26), y_test=(79206,)\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Model Building ---\n",
        "print(\"--- 5. Model Building ---\")\n",
        "\n",
        "# Create the full pipeline including preprocessing and logistic regression model\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)) # Added class_weight and max_iter\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the Logistic Regression model...\")\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "print(\"Model training completed.\")\n",
        "\n",
        "# Display model coefficients (needs careful handling due to one-hot encoding)\n",
        "try:\n",
        "    # Get feature names after one-hot encoding\n",
        "    ohe_feature_names = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
        "    # Combine with numerical features (assuming scaler doesn't change order) and any remainder columns\n",
        "    all_feature_names = numerical_features + list(ohe_feature_names) # Add remainder if needed\n",
        "\n",
        "    coefficients = model_pipeline.named_steps['classifier'].coef_[0]\n",
        "\n",
        "    if len(coefficients) == len(all_feature_names):\n",
        "        coef_df = pd.DataFrame({'Feature': all_feature_names, 'Coefficient': coefficients})\n",
        "        coef_df = coef_df.sort_values(by='Coefficient', ascending=False)\n",
        "        print(\"\\nModel Coefficients (Top 10 positive):\")\n",
        "        print(coef_df.head(10))\n",
        "        print(\"\\nModel Coefficients (Top 10 negative):\")\n",
        "        print(coef_df.tail(10))\n",
        "    else:\n",
        "         print(f\"\\nWarning: Mismatch between coefficient count ({len(coefficients)}) and feature name count ({len(all_feature_names)}). Cannot display coefficients reliably.\")\n",
        "         print(\"Coefficients:\", coefficients)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nCould not extract or display coefficients: {e}\")\n",
        "\n",
        "\n",
        "print(\"-\" * 50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CHXie2BNYZlw",
        "outputId": "30b0525c-ca25-414c-ddd0-500f3af37543"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 5. Model Building ---\n",
            "Training the Logistic Regression model...\n",
            "Model training completed.\n",
            "\n",
            "Model Coefficients (Top 10 positive):\n",
            "                                  Feature  Coefficient\n",
            "26792         emp_title_Correctional Sgt.     2.292275\n",
            "109742  emp_title_Technical Specialist II     2.204899\n",
            "109041         emp_title_Tax Professional     2.189655\n",
            "77494     emp_title_Other World Computing     2.181643\n",
            "44724      emp_title_G4S Secure Solutions     2.176054\n",
            "136685       emp_title_physican assistant     2.167186\n",
            "128034             emp_title_derrick hand     2.138922\n",
            "64726          emp_title_MRI TECHNOLOGIST     2.135241\n",
            "30164              emp_title_Davis County     2.126222\n",
            "19924         emp_title_Central Transport     2.107939\n",
            "\n",
            "Model Coefficients (Top 10 negative):\n",
            "                                       Feature  Coefficient\n",
            "104874           emp_title_Stanford University    -1.696718\n",
            "85840          emp_title_Public Safety Officer    -1.713096\n",
            "42213                   emp_title_Fire Fighter    -1.717904\n",
            "53329                  emp_title_IT Technician    -1.727675\n",
            "41105      emp_title_Federal Bureau of Prisons    -1.774362\n",
            "28239                  emp_title_Customer Care    -1.806255\n",
            "98114   emp_title_Senior Systems Administrator    -1.847333\n",
            "75086             emp_title_Nurse practitioner    -1.948139\n",
            "102773          emp_title_Sr Software Engineer    -1.989272\n",
            "54769         emp_title_Instructional Designer    -2.142123\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Results Evaluation ---\n",
        "print(\"--- 6. Results Evaluation ---\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1] # Probability of positive class\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[NEGATIVE_CLASS, POSITIVE_CLASS]))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[NEGATIVE_CLASS, POSITIVE_CLASS], yticklabels=[NEGATIVE_CLASS, POSITIVE_CLASS])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: confusion_matrix.png\")\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('roc_curve.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: roc_curve.png\")\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
        "pr_auc = auc(recall, precision) # Area under PR curve\n",
        "\n",
        "print(f\"\\nPrecision-Recall AUC Score: {pr_auc:.4f}\") # Note: PR AUC is different from ROC AUC\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (area = {pr_auc:.2f})')\n",
        "# Calculate no-skill line (baseline precision = proportion of positive class in test set)\n",
        "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
        "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', color='red', label=f'No Skill (Precision={no_skill:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.savefig('precision_recall_curve.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: precision_recall_curve.png\")\n",
        "\n",
        "print(\"\\nEvaluation metrics calculated and plots saved.\")\n",
        "print(\"-\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "exvW70urYkac",
        "outputId": "ed0544bb-a845-4501-9c5a-dc45f9d8133d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 6. Results Evaluation ---\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Fully Paid       0.87      0.72      0.79     63671\n",
            " Charged Off       0.33      0.57      0.42     15535\n",
            "\n",
            "    accuracy                           0.69     79206\n",
            "   macro avg       0.60      0.65      0.61     79206\n",
            "weighted avg       0.77      0.69      0.72     79206\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "Saved plot: confusion_matrix.png\n",
            "\n",
            "ROC AUC Score: 0.7054\n",
            "Saved plot: roc_curve.png\n",
            "\n",
            "Precision-Recall AUC Score: 0.3633\n",
            "Saved plot: precision_recall_curve.png\n",
            "\n",
            "Evaluation metrics calculated and plots saved.\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Tradeoff Questions & Insights ---\n",
        "print(\"--- 7. Tradeoff Questions & Insights ---\")\n",
        "\n",
        "# Q6: Primary metric focus for bank?\n",
        "# Discussion: Depends on bank's risk appetite.\n",
        "# - High Precision: Minimize lending to defaulters (reduce NPAs), but might miss good customers (False Negatives). Focus if risk-averse.\n",
        "# - High Recall: Minimize missing out on good customers (reduce False Negatives), but might lend to more defaulters (False Positives). Focus if growth-oriented.\n",
        "# - F1-Score: Balanced measure.\n",
        "# - ROC AUC: Overall model discrimination ability.\n",
        "# Typically, for lending, controlling NPAs is crucial, suggesting a focus on Precision, but Recall is also important for business growth. Often a balance (F1) or careful threshold tuning is needed.\n",
        "print(\"\\nQ6: Primary metric focus?\")\n",
        "print(\"   - Precision: Minimizes lending to actual defaulters (reduces NPAs). Crucial for risk management.\")\n",
        "print(\"   - Recall: Minimizes rejecting potentially good customers. Important for business growth.\")\n",
        "print(\"   - F1-Score: Balances Precision and Recall.\")\n",
        "print(\"   - ROC AUC: Overall model performance across thresholds.\")\n",
        "print(\"   *Recommendation: Focus on Precision to control NPAs, but monitor Recall. Use Precision-Recall curve to find an acceptable tradeoff via threshold tuning.*\")\n",
        "\n",
        "\n",
        "# Q7: How does the gap in precision and recall affect the bank?\n",
        "# Discussion: A large gap often means the model struggles with one aspect more than the other.\n",
        "# - High Precision, Low Recall: Bank is very conservative, avoids bad loans but misses many good loan opportunities, impacting revenue/growth.\n",
        "# - Low Precision, High Recall: Bank is aggressive, captures most good loans but also approves many bad loans, leading to high NPAs and financial losses.\n",
        "print(\"\\nQ7: Effect of Precision-Recall Gap:\")\n",
        "print(\"   - High Precision, Low Recall: Conservative lending, low NPAs, missed revenue opportunities.\")\n",
        "print(\"   - Low Precision, High Recall: Aggressive lending, high revenue potential, high NPAs and losses.\")\n",
        "print(\"   *The gap highlights the direct tradeoff between risk (NPAs) and opportunity (interest income).*\")\n",
        "# Q8: Features heavily affecting the outcome? (Based on coefficients)\n",
        "print(\"\\nQ8: Features potentially affecting the outcome (based on coefficient magnitude):\")\n",
        "# Re-print top/bottom coefficients if available\n",
        "if 'coef_df' in locals():\n",
        "     print(\"   - Top Positive Coefficients (suggesting higher default risk):\")\n",
        "     print(coef_df.head(5))\n",
        "     print(\"\\n   - Top Negative Coefficients (suggesting lower default risk):\")\n",
        "     print(coef_df.tail(5))\n",
        "else:\n",
        "     print(\"   - Coefficient data not available for display.\")\n",
        "# Q9: Will results be affected by geographical location?\n",
        "# Discussion: State was extracted and included. Its significance depends on coefficients.\n",
        "print(\"\\nQ9: Affected by geographical location?\")\n",
        "print(\"   - The 'state' feature was extracted from the address and included in the model.\")\n",
        "print(\"   - *Answer: Yes, geographical location (state) can affect the outcome if the 'state' feature shows significance in the model (check coefficients). This model now attempts to capture state-level effects.*\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QBtJEXdqYrjp",
        "outputId": "64306d1a-66cb-42ae-e809-bf05be070da4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 7. Tradeoff Questions & Insights ---\n",
            "\n",
            "Q6: Primary metric focus?\n",
            "   - Precision: Minimizes lending to actual defaulters (reduces NPAs). Crucial for risk management.\n",
            "   - Recall: Minimizes rejecting potentially good customers. Important for business growth.\n",
            "   - F1-Score: Balances Precision and Recall.\n",
            "   - ROC AUC: Overall model performance across thresholds.\n",
            "   *Recommendation: Focus on Precision to control NPAs, but monitor Recall. Use Precision-Recall curve to find an acceptable tradeoff via threshold tuning.*\n",
            "\n",
            "Q7: Effect of Precision-Recall Gap:\n",
            "   - High Precision, Low Recall: Conservative lending, low NPAs, missed revenue opportunities.\n",
            "   - Low Precision, High Recall: Aggressive lending, high revenue potential, high NPAs and losses.\n",
            "   *The gap highlights the direct tradeoff between risk (NPAs) and opportunity (interest income).*\n",
            "\n",
            "Q8: Features potentially affecting the outcome (based on coefficient magnitude):\n",
            "   - Top Positive Coefficients (suggesting higher default risk):\n",
            "                                  Feature  Coefficient\n",
            "26792         emp_title_Correctional Sgt.     2.292275\n",
            "109742  emp_title_Technical Specialist II     2.204899\n",
            "109041         emp_title_Tax Professional     2.189655\n",
            "77494     emp_title_Other World Computing     2.181643\n",
            "44724      emp_title_G4S Secure Solutions     2.176054\n",
            "\n",
            "   - Top Negative Coefficients (suggesting lower default risk):\n",
            "                                       Feature  Coefficient\n",
            "28239                  emp_title_Customer Care    -1.806255\n",
            "98114   emp_title_Senior Systems Administrator    -1.847333\n",
            "75086             emp_title_Nurse practitioner    -1.948139\n",
            "102773          emp_title_Sr Software Engineer    -1.989272\n",
            "54769         emp_title_Instructional Designer    -2.142123\n",
            "\n",
            "Q9: Affected by geographical location?\n",
            "   - The 'state' feature was extracted from the address and included in the model.\n",
            "   - *Answer: Yes, geographical location (state) can affect the outcome if the 'state' feature shows significance in the model (check coefficients). This model now attempts to capture state-level effects.*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Actionable Insights & Recommendations ---\n",
        "print(\"\\n--- 8. Actionable Insights & Recommendations ---\")\n",
        "print(\"1.  **Focus on Precision:** Prioritize minimizing loans to likely defaulters (high precision) to control NPAs, even if it means missing some potential good customers. Use the Precision-Recall curve to select an appropriate probability threshold.\")\n",
        "print(\"2.  **Key Feature Monitoring:** Closely monitor features identified by the model as strong predictors of default (features with large positive coefficients) during the underwriting process.\")\n",
        "print(\"3.  **High-Cardinality Features:** Be cautious interpreting coefficients for highly granular features like 'emp_title' or 'state'. Consider grouping less frequent categories or using alternative encoding methods (e.g., target encoding) in future iterations to improve model stability and interpretability.\")\n",
        "print(\"4.  **Data Quality:** Address missing values, especially in important fields like `mort_acc` and `emp_length`. The current imputation strategy (median/constant) is a baseline; more sophisticated methods could be explored.\")\n",
        "print(\"5.  **Model Iteration:** This Logistic Regression model is a baseline. Explore more complex models (e.g., Gradient Boosting, Random Forests) which might capture non-linear relationships and improve predictive performance.\")\n",
        "print(\"6.  **Feature Expansion:** Consider engineering additional features, such as interaction terms between key variables or deriving insights from loan purpose/title text data.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- End of Analysis Script ---\")\n",
        "\n",
        "# Note: Removed the incorrect \"Initial Questions Recap\" section.\n",
        "# The correct answers were printed after the initial data load.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pAithIdkYsqq",
        "outputId": "199602a2-84df-4133-f513-989258c03986"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 8. Actionable Insights & Recommendations ---\n",
            "1.  **Focus on Precision:** Prioritize minimizing loans to likely defaulters (high precision) to control NPAs, even if it means missing some potential good customers. Use the Precision-Recall curve to select an appropriate probability threshold.\n",
            "2.  **Key Feature Monitoring:** Closely monitor features identified by the model as strong predictors of default (features with large positive coefficients) during the underwriting process.\n",
            "3.  **High-Cardinality Features:** Be cautious interpreting coefficients for highly granular features like 'emp_title' or 'state'. Consider grouping less frequent categories or using alternative encoding methods (e.g., target encoding) in future iterations to improve model stability and interpretability.\n",
            "4.  **Data Quality:** Address missing values, especially in important fields like `mort_acc` and `emp_length`. The current imputation strategy (median/constant) is a baseline; more sophisticated methods could be explored.\n",
            "5.  **Model Iteration:** This Logistic Regression model is a baseline. Explore more complex models (e.g., Gradient Boosting, Random Forests) which might capture non-linear relationships and improve predictive performance.\n",
            "6.  **Feature Expansion:** Consider engineering additional features, such as interaction terms between key variables or deriving insights from loan purpose/title text data.\n",
            "\n",
            "--- End of Analysis Script ---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}